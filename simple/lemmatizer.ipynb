{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohnM8h1UoACE",
        "outputId": "93563f38-b85a-41c7-c632-85622e9a59c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import random\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Lowercase, remove punctuation, and lemmatize the input text.\"\"\"\n",
        "    text = text.lower()\n",
        "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    # Lemmatize the tokens\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Join the tokens back into a string\n",
        "    cleaned_text = \" \".join(lemmatized_tokens)\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "qeNTxdohpmgy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "K4WDixWO8W2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses = {\n",
        "    \"hello\": [\"Hi there!\", \"Hello!\", \"Greetings!\"],\n",
        "    \"how are you\": [\"I'm doing well, thank you!\", \"I'm fine, thanks for asking.\", \"I'm good.\"],\n",
        "    \"what is your name\": [\"I am a chatbot.\", \"I don't have a name.\"],\n",
        "    \"bye\": [\"Goodbye!\", \"See you later!\", \"Farewell!\"],\n",
        "    \"tell me a joke\": [\"Why don't scientists trust atoms? Because they make up everything!\", \"What do you call a lazy kangaroo? Pouch potato!\"],\n",
        "    \"what is the weather like\": [\"I'm sorry, I don't have information about the weather.\", \"I am unable to provide weather information at this time.\"],\n",
        "    re.compile(r\"i be feel (.*)\"): [\"I'm sorry to hear you're feeling {}.  I hope you feel better soon.\",\n",
        "                             \"It's okay to not feel okay. Is there anything I can do to help you feel better?\" ]\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "2Yk1bpg2pwTn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "import random\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Lowercase, remove punctuation, and lemmatize the input text.\"\"\"\n",
        "    text = text.lower()\n",
        "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
        "\n",
        "    # Tokenize the text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    # Lemmatize the tokens\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # Join the tokens back into a string\n",
        "    cleaned_text = \" \".join(lemmatized_tokens)\n",
        "    return cleaned_text\n",
        "\n",
        "responses = {\n",
        "    \"hello\": [\"Hi there!\", \"Hello!\", \"Greetings!\"],\n",
        "    \"how are you\": [\"I'm doing well, thank you!\", \"I'm fine, thanks for asking.\", \"I'm good.\"],\n",
        "    \"what is your name\": [\"I am a chatbot.\", \"I don't have a name.\"],\n",
        "    \"bye\": [\"Goodbye!\", \"See you later!\", \"Farewell!\"],\n",
        "    \"tell me a joke\": [\"Why don't scientists trust atoms? Because they make up everything!\", \"What do you call a lazy kangaroo? Pouch potato!\"],\n",
        "    \"what is the weather like\": [\"I'm sorry, I don't have information about the weather.\", \"I am unable to provide weather information at this time.\"],\n",
        "    re.compile(r\"i be feel (.*)\"): [\"I'm sorry to hear you're feeling {}.  I hope you feel better soon.\",\n",
        "                             \"It's okay to not feel okay. Is there anything I can do to help you feel better?\" ]\n",
        "\n",
        "}\n",
        "\n",
        "def chatbot_response(user_input):\n",
        "    \"\"\"Generates a response based on the user's input.\"\"\"\n",
        "    cleaned_input = clean_text(user_input)\n",
        "\n",
        "    for pattern, response_list in responses.items():\n",
        "        if isinstance(pattern, str) and pattern in cleaned_input:\n",
        "            return random.choice(response_list)\n",
        "        elif hasattr(pattern, 'search'):\n",
        "            match = pattern.search(cleaned_input)\n",
        "            if match:\n",
        "                return random.choice(response_list).format(match.group(1))\n",
        "\n",
        "    return \"I'm sorry, I don't understand. Can you rephrase that?\"  # Default response\n",
        "\n",
        "def start_chat():\n",
        "    \"\"\"Starts the chatbot conversation.\"\"\"\n",
        "    print(\"Chatbot: Hello! How can I help you today? (Type 'bye' to exit)\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == \"bye\":\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Chatbot:\", chatbot_response(user_input))\n",
        "\n",
        "# Start the chat\n",
        "start_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_o89DRjpxtw",
        "outputId": "c6abf973-e145-406e-c875-5e8c49557ad6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: Hello! How can I help you today? (Type 'bye' to exit)\n",
            "You: Hello\n",
            "Chatbot: Greetings!\n",
            "You: How are you?\n",
            "Chatbot: I'm good.\n",
            "You: Tell me a joke\n",
            "Chatbot: Why don't scientists trust atoms? Because they make up everything!\n",
            "You: bye\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ]
    }
  ]
}